{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "Machine learning provides a computer with data, rather than explicit\n",
    "instructions. Using these data, the computer learns to recognize\n",
    "patterns and becomes able to execute tasks on its own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "\n",
    "Supervised learning is a task where a computer learns a function that\n",
    "maps inputs to outputs based on a dataset of input-output pairs.\n",
    "\n",
    "There are multiple tasks under supervised learning, and one of those is\n",
    "**Classification**. This is a task where the function maps an input to a\n",
    "discrete output. For example, given some information on humidity and air\n",
    "pressure for a particular day (input), the computer decides whether it\n",
    "will rain that day or not (output). The computer does this after\n",
    "training on a dataset with multiple days where humidity and air pressure\n",
    "are already mapped to whether it rained or not.\n",
    "\n",
    "This task can be formalized as follows. We observe nature, where a\n",
    "function *f(humidity, pressure)* maps the input to a discrete value,\n",
    "either Rain or No Rain. This function is hidden from us, and it is\n",
    "probably affected by many other variables that we don’t have access to.\n",
    "Our goal is to create function *h(humidity, pressure)* that can\n",
    "approximate the behavior of function *f*. Such a task can be visualized\n",
    "by plotting days on the dimensions of humidity and rain (the input),\n",
    "coloring each data point in blue if it rained that day and in red if it\n",
    "didn’t rain that day (the output). The white data point has only the\n",
    "input, and the computer needs to figure out the output.\n",
    "\n",
    "![Classification](https://cs50.harvard.edu/ai/2024/notes/4/classification.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest-Neighbor Classification\n",
    "\n",
    "One way of solving a task like the one described above is by assigning\n",
    "the variable in question the value of the closest observation. So, for\n",
    "example, the white dot on the graph above would be colored blue, because\n",
    "the nearest observed dot is blue as well. This might work well some\n",
    "times, but consider the graph below.\n",
    "\n",
    "![Nearest Neighbor Classification](https://cs50.harvard.edu/ai/2024/notes/4/nearestneighbor.png)\n",
    "\n",
    "Following the same strategy, the white dot should be colored red,\n",
    "because the nearest observation to it is red as well. However, looking\n",
    "at the bigger picture, it looks like most of the other observations\n",
    "around it are blue, which might give us the intuition that blue is a\n",
    "better prediction in this case, even though the closest observation is\n",
    "red.\n",
    "\n",
    "One way to get around the limitations of nearest-neighbor classification\n",
    "is by using **k-nearest-neighbors classification**, where the dot is\n",
    "colored based on the most frequent color of the *k* nearest neighbors.\n",
    "It is up to the programmer to decide what *k* is. Using a 3-nearest\n",
    "neighbors classification, for example, the white dot above will be\n",
    "colored blue, which intuitively seems like a better decision.\n",
    "\n",
    "A drawback of the k-nearest-neighbors classification is that, using a\n",
    "naive approach, the algorithm will have to measure the distance of every\n",
    "single point to the point in question, which is computationally\n",
    "expensive. This can be sped up by using data structures that enable\n",
    "finding neighbors more quickly or by pruning irrelevant observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron Learning\n",
    "\n",
    "Another way of going about a classification problem, as opposed to the\n",
    "nearest-neighbor strategy, is looking at the data as a whole and trying\n",
    "to create a decision boundary. In two-dimensional data, we can draw a\n",
    "line between the two types of observations. Every additional data point\n",
    "will be classified based on the side of the line on which it is plotted.\n",
    "\n",
    "![Decision Boundary](https://cs50.harvard.edu/ai/2024/notes/4/decisionboundary.png)\n",
    "\n",
    "The drawback to this approach is that data are messy, and it is rare\n",
    "that one can draw a line and neatly divide the classes into two\n",
    "observations without any mistakes. Often, we will compromise, drawing a\n",
    "boundary that separates the observations correctly more often than not,\n",
    "but still occasionally misclassifies them.\n",
    "\n",
    "In this case, the input of\n",
    "\n",
    "- *x₁* = Humidity\n",
    "- *x₂* = Pressure\n",
    "\n",
    "will be given to a hypothesis function *h(x₁, x₂)*, which will output\n",
    "its prediction of whether it is going to rain that day or not. It will\n",
    "do so by checking on which side of the decision boundary the observation\n",
    "falls. Formally, the function will weight each of the inputs with an\n",
    "addition of a constant, ending in a linear equation of the following\n",
    "form:\n",
    "\n",
    "- Rain w₀ + w₁x₁ + w₂x₂ ≥ 0\n",
    "- No Rain otherwise\n",
    "\n",
    "Often, the output variable will be coded as 1 and 0, where if the\n",
    "equation yields more than 0, the output is 1 (Rain), and 0 otherwise (No\n",
    "Rain).\n",
    "\n",
    "The weights and values are represented by vectors, which are sequences\n",
    "of numbers (which can be stored in lists or tuples in Python). We\n",
    "produce a Weight Vector **w**: (w₀, w₁, w₂), and getting to the best\n",
    "weight vector is the goal of the machine learning algorithm. We also\n",
    "produce an Input Vector **x**: (1, x₁, x₂).\n",
    "\n",
    "We take the dot product of the two vectors. That is, we multiply each\n",
    "value in one vector by the corresponding value in the second vector,\n",
    "arriving at the expression above: w₀ + w₁x₁ + w₂x₂. The first value in\n",
    "the input vector is 1 because, when multiplied by the weight vector w₀,\n",
    "we want to keep it a constant.\n",
    "\n",
    "Thus, we can represent our hypothesis function the following way:\n",
    "\n",
    "![Dot Product Equation](https://cs50.harvard.edu/ai/2024/notes/4/dotproduct.png)\n",
    "\n",
    "Since the goal of the algorithm is to find the best weight vector, when\n",
    "the algorithm encounters new data it updates the current weights. It\n",
    "does so using the **perceptron learning rule**:\n",
    "\n",
    "![Perceptron Learning Rule](https://cs50.harvard.edu/ai/2024/notes/4/perceptronlearning.png)\n",
    "\n",
    "The important takeaway from this rule is that for each data point, we\n",
    "adjust the weights to make our function more accurate. The details,\n",
    "which are not as critical to our point, are that each weight is set to\n",
    "be equal to itself plus some value in parentheses. Here, y stands for\n",
    "the observed value while the hypothesis function stands for the\n",
    "estimate. If they are identical, this whole term is equal to zero, and\n",
    "thus the weight is not changed. If we underestimated (calling No Rain\n",
    "while Rain was observed), then the value in the parentheses will be 1\n",
    "and the weight will increase by the value of xᵢ scaled by α the learning\n",
    "coefficient. If we overestimated (calling Rain while No Rain was\n",
    "observed), then the value in the parentheses will be -1 and the weight\n",
    "will decrease by the value of x scaled by α. The higher α, the stronger\n",
    "the influence each new event has on the weight.\n",
    "\n",
    "The result of this process is a threshold function that switches from 0\n",
    "to 1 once the estimated value crosses some threshold.\n",
    "\n",
    "![Hard Threshold](https://cs50.harvard.edu/ai/2024/notes/4/hardthreshold.png)\n",
    "\n",
    "The problem with this type of function is that it is unable to express\n",
    "uncertainty, since it can only be equal to 0 or to 1. It employs a\n",
    "**hard threshold**. A way to go around this is by using a logistic\n",
    "function, which employs a **soft threshold**. A logistic function can\n",
    "yield a real number between 0 and 1, which will express confidence in\n",
    "the estimate. The closer the value to 1, the more likely it is to rain.\n",
    "\n",
    "![Soft Threshold](https://cs50.harvard.edu/ai/2024/notes/4/softthreshold.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines\n",
    "\n",
    "In addition to nearest-neighbor and linear regression, another approach\n",
    "to classification is the Support Vector Machine. This approach uses an\n",
    "additional vector (support vector) near the decision boundary to make\n",
    "the best decision when separating the data. Consider the example below.\n",
    "\n",
    "![Support Vector Machine](https://cs50.harvard.edu/ai/2024/notes/4/supportvector.png)\n",
    "\n",
    "All the decision boundaries work in that they separate the data without\n",
    "any mistakes. However, are they equally as good? The two leftmost\n",
    "decision boundaries are very close to some of the observations. This\n",
    "means that a new data point that differs only slightly from one group\n",
    "can be wrongly classified as the other. As opposed to that, the\n",
    "rightmost decision boundary keeps the most distance from each of the\n",
    "groups, thus giving the most leeway for variation within it. This type\n",
    "of boundary, which is as far as possible from the two groups it\n",
    "separates, is called the **Maximum Margin Separator**.\n",
    "\n",
    "Another benefit of support vector machines is that they can represent\n",
    "decision boundaries with more than two dimensions, as well as non-linear\n",
    "decision boundaries, such as below.\n",
    "\n",
    "![Circle Decision Boundary](https://cs50.harvard.edu/ai/2024/notes/4/circleboundary.png)\n",
    "\n",
    "To summarize, there are multiple ways to go about classification\n",
    "problems, with no one being always better than the other. Each has their\n",
    "drawbacks and might prove more useful than others in specific\n",
    "situations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "Regression is a supervised learning task of a function that maps an\n",
    "input point to a continuous value, some real number. This differs from\n",
    "classification in that classification problems map an input to discrete\n",
    "values (Rain or No Rain).\n",
    "\n",
    "For example, a company might use regression to answer the question of\n",
    "how money spent advertising predicts money earned in sales. In this\n",
    "case, an observed function *f(advertising)* represents the observed\n",
    "income following some money that was spent in advertising (note that the\n",
    "function can take more than one input variable). These are the data that\n",
    "we start with. With this data, we want to come up with a hypothesis\n",
    "function *h(advertising)* that will try to approximate the behavior of\n",
    "function *f*. *h* will generate a line whose goal is not to separate\n",
    "between types of observations, but to predict, based on the input, what\n",
    "will be the value of the output.\n",
    "\n",
    "![Regression](https://cs50.harvard.edu/ai/2024/notes/4/regression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions\n",
    "\n",
    "Loss functions are a way to quantify the utility lost by any of the\n",
    "decision rules above. The less accurate the prediction, the larger the\n",
    "loss.\n",
    "\n",
    "For classification problems, we can use a **0-1 Loss Function**.\n",
    "\n",
    "- *L*(actual, predicted):\n",
    "  - 0 if actual = predicted\n",
    "  - 1 otherwise\n",
    "\n",
    "In words, this function gains value when the prediction isn’t correct\n",
    "and doesn’t gain value when it is correct (i.e. when the observed and\n",
    "predicted values match).\n",
    "\n",
    "![0-1 Loss Function](https://cs50.harvard.edu/ai/2024/notes/4/01loss.png)\n",
    "\n",
    "In the example above, the days that are valued at 0 are the ones where\n",
    "we predicted the weather correctly (rainy days are below the line and\n",
    "not rainy days are above the line). However, days when it didn’t rain\n",
    "below the line and days when it did rain above it are the ones that we\n",
    "failed to predict. We give each one the value of 1 and sum them up to\n",
    "get an empirical estimate of how lossy our decision boundary is.\n",
    "\n",
    "L₁ and L₂ loss functions can be used when predicting a continuous value.\n",
    "In this case, we are interested in quantifying for each prediction *how\n",
    "much* it differed from the observed value. We do this by taking either\n",
    "the absolute value or the squared value of the observed value minus the\n",
    "predicted value (i.e. how far the prediction was from the observed\n",
    "value).\n",
    "\n",
    "- L₁: *L*(actual, predicted) = \\|actual - predicted\\|\n",
    "- L₂: *L*(actual, predicted) = (actual - predicted)²\n",
    "\n",
    "One can choose the loss function that serves their goals best. L₂\n",
    "penalizes outliers more harshly than L₁ because it squares the the\n",
    "difference. L₁ can be visualized by summing the distances from each\n",
    "observed point to the predicted point on the regression line:\n",
    "\n",
    "![L₁](https://cs50.harvard.edu/ai/2024/notes/4/l1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "\n",
    "Overfitting is when a model fits the training data so well that it fails\n",
    "to generalize to other data sets. In this sense, loss functions are a\n",
    "double edged sword. In the two examples below, the loss function is\n",
    "minimized such that the loss is equal to 0. However, it is unlikely that\n",
    "it will fit new data well.\n",
    "\n",
    "![Overfitting](https://cs50.harvard.edu/ai/2024/notes/4/overfitting.png)\n",
    "\n",
    "For example, in the left graph, a dot next to the red one at the bottom\n",
    "of the screen is likely to be Rain (blue). However, with the overfitted\n",
    "model, it will be classified as No Rain (red)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "\n",
    "Regularization is the process of penalizing hypotheses that are more\n",
    "complex to favor simpler, more general hypotheses. We use regularization\n",
    "to avoid overfitting.\n",
    "\n",
    "In regularization, we estimate the cost of the hypothesis function h by\n",
    "adding up its loss and a measure of its complexity.\n",
    "\n",
    "*cost*(h) = *loss*(h) + λ*complexity*(h)\n",
    "\n",
    "Lambda (λ) is a constant that we can use to modulate how strongly to\n",
    "penalize for complexity in our cost function. The higher λ is, the more\n",
    "costly complexity is.\n",
    "\n",
    "One way to test whether we overfitted the model is with **Holdout Cross\n",
    "Validation**. In this technique, we split all the data in two: a\n",
    "**training set** and a **test set**. We run the learning algorithm on\n",
    "the training set, and then see how well it predicts the data in the test\n",
    "set. The idea here is that by testing on data that were not used in\n",
    "training, we can a measure how well the learning generalizes.\n",
    "\n",
    "The downside of holdout cross validation is that we don’t get to train\n",
    "the model on half the data, since it is used for evaluation purposes. A\n",
    "way to deal with this is using ***k*-Fold Cross-Validation**. In this\n",
    "process, we divide the data into k sets. We run the training k times,\n",
    "each time leaving out one dataset and using it as a test set. We end up\n",
    "with k different evaluations of our model, which we can average and get\n",
    "an estimate of how our model generalizes without losing any data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learn\n",
    "\n",
    "As often is the case with Python, there are multiple libraries that\n",
    "allow us to conveniently use machine learning algorithms. One of such\n",
    "libraries is scikit-learn.\n",
    "\n",
    "As an example, we are going to use a\n",
    "[CSV](https://en.wikipedia.org/wiki/Comma-separated_values) dataset of\n",
    "counterfeit banknotes.\n",
    "\n",
    "![Banknotes](https://cs50.harvard.edu/ai/2024/notes/4/banknotes.png)\n",
    "\n",
    "The four left columns are data that we can use to predict whether a note\n",
    "is genuine or counterfeit, which is external data provided by a human,\n",
    "coded as 0 and 1. Now we can train our model on this data set and see if\n",
    "we can predict whether new banknotes are genuine or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "model = Perceptron()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that after importing the libraries, we can choose which model to\n",
    "use. The rest of the code will stay the same. SVC stands for Support\n",
    "Vector Classifier (which we know as support vector machine). The\n",
    "KNeighborsClassifier uses the k-neighbors strategy, and requires as\n",
    "input the number of neighbors it should consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model Perceptron\n",
      "Correct: 534\n",
      "Incorrect: 14\n",
      "Accuracy: 97.45%\n"
     ]
    }
   ],
   "source": [
    "# Read data in from file\n",
    "with open(\"banknotes/banknotes.csv\", encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "\n",
    "    data = []\n",
    "    for row in reader:\n",
    "        data.append(\n",
    "            {\n",
    "                \"evidence\": [float(cell) for cell in row[:4]],\n",
    "                \"label\": \"Authentic\" if row[4] == \"0\" else \"Counterfeit\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Separate data into training and testing groups\n",
    "holdout = int(0.40 * len(data))\n",
    "random.shuffle(data)\n",
    "testing = data[:holdout]\n",
    "training = data[holdout:]\n",
    "\n",
    "# Train model on training set\n",
    "X_training = [row[\"evidence\"] for row in training]\n",
    "y_training = [row[\"label\"] for row in training]\n",
    "model.fit(X_training, y_training)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "X_testing = [row[\"evidence\"] for row in testing]\n",
    "y_testing = [row[\"label\"] for row in testing]\n",
    "predictions = model.predict(X_testing)\n",
    "\n",
    "# Compute how well we performed\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "total = 0\n",
    "for actual, predicted in zip(y_testing, predictions):\n",
    "    total += 1\n",
    "    if actual == predicted:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "\n",
    "# Print results\n",
    "print(f\"Results for model {type(model).__name__}\")\n",
    "print(f\"Correct: {correct}\")\n",
    "print(f\"Incorrect: {incorrect}\")\n",
    "print(f\"Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This manual version of running the algorithm can be found in the source\n",
    "code for this lecture under banknotes0.py. Since the algorithm is used\n",
    "often in a similar way, scikit-learn contains additional functions that\n",
    "make the code even more succinct and easy to use, and this version can\n",
    "be found under banknotes1.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model Perceptron\n",
      "Correct: 521\n",
      "Incorrect: 28\n",
      "Accuracy: 94.90%\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model = Perceptron()\n",
    "# model = svm.SVC()\n",
    "# model = KNeighborsClassifier(n_neighbors=1)\n",
    "# model = GaussianNB()\n",
    "\n",
    "# Read data in from file\n",
    "with open(\"banknotes/banknotes.csv\", encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "\n",
    "    data = []\n",
    "    for row in reader:\n",
    "        data.append(\n",
    "            {\n",
    "                \"evidence\": [float(cell) for cell in row[:4]],\n",
    "                \"label\": \"Authentic\" if row[4] == \"0\" else \"Counterfeit\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Separate data into training and testing groups\n",
    "evidence = [row[\"evidence\"] for row in data]\n",
    "labels = [row[\"label\"] for row in data]\n",
    "\n",
    "X_training, X_testing, y_training, y_testing = train_test_split(\n",
    "    evidence, labels, test_size=0.4\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "model.fit(X_training, y_training)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "predictions = model.predict(X_testing)\n",
    "\n",
    "# Compute how well we performed\n",
    "correct = (y_testing == predictions).sum()\n",
    "incorrect = (y_testing != predictions).sum()\n",
    "total = len(predictions)\n",
    "\n",
    "# Print results\n",
    "print(f\"Results for model {type(model).__name__}\")\n",
    "print(f\"Correct: {correct}\")\n",
    "print(f\"Incorrect: {incorrect}\")\n",
    "print(f\"Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning\n",
    "\n",
    "Reinforcement learning is another approach to machine learning, where\n",
    "after each action, the agent gets feedback in the form of reward or\n",
    "punishment (a positive or a negative numerical value).\n",
    "\n",
    "![Reinforcement Learning](https://cs50.harvard.edu/ai/2024/notes/4/reinforcement.png)\n",
    "\n",
    "The learning process starts by the environment providing a state to the\n",
    "agent. Then, the agent performs an action on the state. Based on this\n",
    "action, the environment will return a state and a reward to the agent,\n",
    "where the reward can be positive, making the behavior more likely in the\n",
    "future, or negative (i.e. punishment), making the behavior less likely\n",
    "in the future.\n",
    "\n",
    "This type of algorithm can be used to train walking robots, for example,\n",
    "where each step returns a positive number (reward) and each fall a\n",
    "negative number (punishment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Decision Processes\n",
    "\n",
    "Reinforcement learning can be viewed as a Markov decision process,\n",
    "having the following properties:\n",
    "\n",
    "- Set of states ***S***\n",
    "- Set of actions ***Actions(S)***\n",
    "- Transition model ***P(s’ \\| s, a)***\n",
    "- Reward function ***R(s, a, s’)***\n",
    "\n",
    "For example, consider the following task:\n",
    "\n",
    "![Markov Decision Process Demo](https://cs50.harvard.edu/ai/2024/notes/4/markov.png)\n",
    "\n",
    "The agent is the yellow circle, and it needs to get to the green square\n",
    "while avoiding the red squares. Every single square in the task is a\n",
    "state. Moving up, down, or to the sides is an action. The transition\n",
    "model gives us the new state after performing an action, and the reward\n",
    "function is what kind of feedback the agent gets. For example, if the\n",
    "agent chooses to go right, it will step on a red square and get negative\n",
    "feedback. This means that the agent will learn that, when in the state\n",
    "of being in the bottom-left square, it should avoid going right. This\n",
    "way, the agent will start exploring the space, learning which\n",
    "state-action pairs it should avoid. The algorithm can be probabilistic,\n",
    "choosing to take different actions in different states based on some\n",
    "probability that’s being increased or decreased based on reward. When\n",
    "the agent reaches the green square, it will get a positive reward,\n",
    "learning that it is favorable to take the action it took in the previous\n",
    "state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning\n",
    "\n",
    "Q-Learning is one model of reinforcement learning, where a function\n",
    "***Q(s, a)*** outputs an estimate of the value of taking action *a* in\n",
    "state *s*.\n",
    "\n",
    "The model starts with all estimated values equal to 0 (***Q(s,a)* = 0**\n",
    "for all *s, a*). When an action is taken and a reward is received, the\n",
    "function does two things: 1) it estimates the value of ***Q(s, a)***\n",
    "based on current reward and expected future rewards, and 2) updates\n",
    "***Q(s, a)*** to take into account both the old estimate and the new\n",
    "estimate. This gives us an algorithm that is capable of improving upon\n",
    "its past knowledge without starting from scratch.\n",
    "\n",
    "***Q(s, a) ⟵ Q(s, a) + α(new value estimate - Q(s, a))***\n",
    "\n",
    "The updated value of ***Q(s, a)*** is equal to the previous value of\n",
    "***Q(s, a)*** in addition to some updating value. This value is\n",
    "determined as the difference between the new value and the old value,\n",
    "multiplied by α, a learning coefficient. When α = 1 the new estimate\n",
    "simply overwrites the old one. When α = 0, the estimated value is never\n",
    "updated. By raising and lowering α, we can determine how fast previous\n",
    "knowledge is being updated by new estimates.\n",
    "\n",
    "The new value estimate can be expressed as a sum of the reward (r) and\n",
    "the future reward estimate. To get the future reward estimate, we\n",
    "consider the new state that we got after taking the last action, and add\n",
    "the estimate of the action in this new state that will bring to the\n",
    "highest reward. This way, we estimate the utility of making action *a*\n",
    "in state *s* not only by the reward it received, but also by the\n",
    "expected utility of the next step. The value of the future reward\n",
    "estimate can sometimes appear with a coefficient gamma that controls how\n",
    "much future rewards are valued. We end up with the following equation:\n",
    "\n",
    "![Q Learning Formula](https://cs50.harvard.edu/ai/2024/notes/4/qlearning.png)\n",
    "\n",
    "A **Greedy Decision-Making** algorithm completely discounts the future\n",
    "estimated rewards, instead always choosing the action ***a*** in current\n",
    "state ***s*** that has the highest ***Q(s, a)***.\n",
    "\n",
    "This brings us to discuss the **Explore vs. Exploit** tradeoff. A greedy\n",
    "algorithm always exploits, taking the actions that are already\n",
    "established to bring to good outcomes. However, it will always follow\n",
    "the same path to the solution, never finding a better path. Exploration,\n",
    "on the other hand, means that the algorithm may use a previously\n",
    "unexplored route on its way to the target, allowing it to discover more\n",
    "efficient solutions along the way. For example, if you listen to the\n",
    "same songs every single time, you know you will enjoy them, but you will\n",
    "never get to know new songs that you might like even more!\n",
    "\n",
    "To implement the concept of exploration and exploitation, we can use the\n",
    "**ε (epsilon) greedy** algorithm. In this type of algorithm, we set ε\n",
    "equal to how often we want to move randomly. With probability 1-ε, the\n",
    "algorithm chooses the best move (exploitation). With probability ε, the\n",
    "algorithm chooses a random move (exploration).\n",
    "\n",
    "Another way to train a reinforcement learning model is to give feedback\n",
    "not upon every move, but upon the end of the whole process. For example,\n",
    "consider a game of Nim. In this game, different numbers of objects are\n",
    "distributed between piles. Each player takes any number of objects from\n",
    "any one single pile, and the player who takes the last object looses. In\n",
    "such a game, an untrained AI will play randomly, and it will be easy to\n",
    "win against it. To train the AI, it will start from playing a game\n",
    "randomly, and in the end get a reward of 1 for winning and -1 for\n",
    "losing. When it is trained on 10,000 games, for example, it is already\n",
    "smart enough to be hard to win against it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing training game 1\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m play, train\n\u001b[0;32m----> 3\u001b[0m ai \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m play(ai)\n",
      "File \u001b[0;32m/workspaces/cs50ai/src4/nim/nim.py:177\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m \n\u001b[1;32m    175\u001b[0m     \u001b[38;5;66;03m# Keep track of current state and action\u001b[39;00m\n\u001b[1;32m    176\u001b[0m     state \u001b[38;5;241m=\u001b[39m game\u001b[38;5;241m.\u001b[39mpiles\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 177\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mplayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoose_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpiles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# Keep track of last state and action\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     last[game\u001b[38;5;241m.\u001b[39mplayer][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m state\n",
      "File \u001b[0;32m/workspaces/cs50ai/src4/nim/nim.py:151\u001b[0m, in \u001b[0;36mNimAI.choose_action\u001b[0;34m(self, state, epsilon)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchoose_action\u001b[39m(\u001b[38;5;28mself\u001b[39m, state, epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    137\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m    Given a state `state`, return an action `(i, j)` to take.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03m    options is an acceptable return value.\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from nim.nim import play, train\n",
    "\n",
    "ai = train(10000)\n",
    "play(ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach becomes more computationally demanding when a game has\n",
    "multiple states and possible actions, such as chess. It is infeasible to\n",
    "generate an estimated value for every possible move in every possible\n",
    "state. In this case, we can use a **function approximation**, which\n",
    "allows us to approximate ***Q(s, a)*** using various other features,\n",
    "rather than storing one value for each state-action pair. Thus, the\n",
    "algorithm becomes able to recognize which moves are similar enough so\n",
    "that their estimated value should be similar as well, and use this\n",
    "heuristic in its decision making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning\n",
    "\n",
    "In all the cases we saw before, as in supervised learning, we had data\n",
    "with labels that the algorithm could learn from. For example, when we\n",
    "trained an algorithm to recognize counterfeit notes, each banknote had\n",
    "four variables with different values (the input data) and whether it is\n",
    "counterfeit or not (the label). In unsupervised learning, only the input\n",
    "data is present and the AI learns patterns in these data.\n",
    "\n",
    "**Clustering**\n",
    "\n",
    "Clustering is an unsupervised learning task that takes the input data\n",
    "and organizes it into groups such that similar objects end up in the\n",
    "same group. This can be used, for example, in genetics research, when\n",
    "trying to find similar genes, or in image segmentation, when defining\n",
    "different parts of the image based on similarity between pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means Clustering\n",
    "\n",
    "k-means Clustering is an algorithm to perform a clustering task. It maps\n",
    "all data points in a space, and then randomly places k cluster centers\n",
    "in the space (it is up to the programmer to decide how many; this is the\n",
    "starting state we see on the left). Each cluster center is simply a\n",
    "point in the space. Then, each cluster gets assigned all the points that\n",
    "are closest to its center than to any other center (this is the middle\n",
    "picture). Then, in an iterative process, the cluster center moves to the\n",
    "middle of all these points (the state on the right), and then points are\n",
    "reassigned again to the clusters whose centers are now closest to them.\n",
    "When, after repeating the process, each point remains in the same\n",
    "cluster it was before, we have reached an equilibrium and the algorithm\n",
    "is over, leaving us with points divided between clusters.\n",
    "\n",
    "![k-means Clustering](https://cs50.harvard.edu/ai/2024/notes/4/kclustering.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
